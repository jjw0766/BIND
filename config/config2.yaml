seed: 42
cuda_visible_devices: "1"

# Dataset & Model
dataset_name: jwengr/DACON-Korean-Review-Obfuscation
from_disk: false
base_model_name: Qwen/Qwen3-14B
use_qlora: true

# Training Hyperparameters
mini_batch_size: 16
n_batch: 2
epochs: 10
learning_rate: 0.0001
lora_r: 16
lora_alpha: 32
neftune_alpha: 0

# Sequence Lengths
train_max_length: 256
valid_max_length: 256
use_inference_sentence_tokenizer: true
inference_sentence_max_length: 256
inference_sentence_min_length: 128
inference_sentence_n_overlap: 1

prefix: 'length=256'